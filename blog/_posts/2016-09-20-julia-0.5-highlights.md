---
layout: post
title:  Julia 0.5 Highlights
author: Stefan Karpinski
---

Julia 0.5 is a pivotal release. It introduces more transformative features than any release since Julia's initial public release. Moreover, several of these features set the stage for even more to come in the [lead up to Julia 1.0](https://www.youtube.com/watch?v=5gXMpbY1kJY). In this post, we'll go through some of the major changes in 0.5, including improvements to functional programming, comprehensions, generators, arrays, strings, the standard library, and tooling.

## Functions

Julia has always been a functional language in the technical sense: functions are values that can be passed to and from other functions (i.e. [higher-order functions](https://en.wikipedia.org/wiki/Higher-order_function)) and there is full support for [lambdas](https://en.wikipedia.org/wiki/Anonymous_function). Before this release, however, anonymous and higher-order functions came with a significant performance cost, and in a language that targets high-performance technical computing, that's a problem. So the Julia standard library and ecosystem have been rife with work-arounds to get the expressiveness of functional programming without the performance problems. But the right solution, of course, is to just make functional programming fast – ideally just as fast as the optimal hand-written version of your code would be. In Julia 0.5, it is. And that changes everything.

This change is so important that there will be a separate blog post about it in the coming weeks, explaining how it was accomplished and what kinds of zero-cost abstractions it enables in Julia 0.5, but for now, I'll just tease with a little timing comparison:

    julia> v = rand(10^7);

    julia> double_it_vec(v) = 2v
    double_it_vec (generic function with 1 method)

    julia> double_it_map(v) = map(x->2x, v)
    double_it_map (generic function with 1 method)

    julia> mean([@elapsed(double_it_vec(v)) for _=1:100])
    0.02426630012

    julia> mean([@elapsed(double_it_map(v)) for _=1:100])
    0.023419441759999996

Defining a `double_it` function in terms of a higher-order construct like `map` is now as fast (or even faster) than using a specialize method for vectorized scaling. On 0.4, by constrast, using `map` like this is over 200 times slower than the vectorized version. In this case, writing `2v` is more convenient, and you can keep doing that when it's easier, but many constructs that were previously speclized via code generation, can now simply be *defined* in terms of generic functional constructs. The result is more elegant, more concise, and at least as efficient.

### Return type annotations

You can now annotate method definitions with a return type, like so:

    function clip{T<:Real}(x::T, lo::Real, hi::Real)::T
        if x < lo
            return lo
        elseif x > hi
            return hi
        else
            return x
        end
    end

This has the effect of inserting implicit calls to `convert` to `T` at each return point, in this case ensuring that `clip` always returns a value of the same type as `x`, regardless of the type of `lo` and `hi`:

    julia> clip(0.5, 1, 2)
    1.0

    julia> clip(1.5, 1, 2)
    1.5

    julia> clip(2.5, 1, 2)
    2.0

You may have noticed that the return type here is `T`, which is a type parameter of the `clip` method. Not only is that allowed, but the return type can be an arbitrary expression of values from the outer scope, argument values, and type parameters. For example:

    function clip2(x::Real, lo::Real, hi::Real)::promote_type(typeof(x), typeof(lo), typeof(hi))
        if x < lo
            return lo
        elseif x > hi
            return hi
        else
            return x
        end
    end

    julia> clip2(2, 1, 3)
    2

    julia> clip2(2, 1, 13//5)
    2//1

    julia> clip2(2.5, 1, 13//5)
    2.5

Return type annotations makes it easier to write methods with consistent and predicatble return types – if different branches of your code lead to slightly different return types, the fix is now as simple as putting a single type annotation on the entire method.

### No more ambiguous method warnings

One design decision that any multiple dispatch language must make is how to handle dispatch ambiguities – cases where none of the methods applicable to a given set of arguments is strictly more specific than the rest. For example, suppose a generic function, `f` has the following methods:

    f(a::Int, b::Real) = 1
    f(a::Real, b::Int) = 2

In Julia 0.4 and earlier, when the second method is defined, Julia prints a method ambiguity warning:

    WARNING: New definition
        f(Real, Int64) at none:1
    is ambiguous with:
        f(Int64, Real) at none:1.
    To fix, define
        f(Int64, Int64)
    before the new definition.

This is a fairly conservative choice – it urges people to define a method covering the ambiguous intersection *before* defining these two methods. When this choice was made, we hoped that people would define explicit behaviors for all ambigous cases and all would be well in the world.

Warnings for method ambiguities has turned out to be impractical, however – especially for generic methods that are extended by many different packages. Unrelated packages commonly load independently without any ambiguities, yet when both are loaded simultaneously, ambiguities are created. In Julia 0.4 and earlier, this produced an alarming cascade of warnings. Moreover, these ambiguities cases are generally unlikely to actually occur since the types are unrelated – and if they do occur, a runtime error is the most appropriate recourse. Accordingly, in Julia 0.5 these method definitions for `f` produce no warnings; instead, ambiguous calls raise runtime errors:

    julia> f(3, 4)
    ERROR: MethodError: f(::Int64, ::Int64) is ambiguous. Candidates:
      f(a::Real, b::Int64) at REPL[2]:1
      f(a::Int64, b::Real) at REPL[1]:1
     in eval(::Module, ::Any) at ./boot.jl:231
     in macro expansion at ./REPL.jl:92 [inlined]
     in (::Base.REPL.##1#2{Base.REPL.REPLBackend})() at ./event.jl:46

This improves the experience of using the Julia package ecosystem considerably since loading unrelated packages no longer runs the risk of spewing forth a flood of ambiguity warnings. And of course, fewer unnecessary warnings means that real warnings that you *should* be concerned about are less likely to get lost in the noise, which makes for safer and more reliable programs.

## Comprehensions & Generators

In examples above, we used an array comprehension to time an expression multiple times, producing an array of elapsed times. We then applied the `mean` function to that array to get an average elapsed time. But an average can easily be computed over streamed data, accumulating only the sum and count of values, so this code could be expressed with constant overhead by interleaving the computation of the mean with the evaluation of the expression producing values. Prior to Julia 0.5, the easiest way to express a streamed computation like this was to write out an explicit for loop. In Julia 0.5, on the other hand, if you leave the `[` and `]` around an array comprehension out, you get a *generator expression*, which instead of producing an array of values, can be iterated over yielding one value at a time. Since many standard library functions work with arbitrary iterable collections – including generators – writing the streamed version of this computation, and many others, is now as easy as deleting two square brackets:

    julia> mean(@elapsed(double_it_map(v)) for _=1:100)
    0.022724940119999995

This avoids allocating a temporary array of elapsed times. Instead the expression `@elapsed(double_it_map(v))` is evaluated each time the `mean` function is ready to accept a new value. The syntactic similarity between array comprehensions and generator expressions makes it trivial to move back and forth between the two styles of computation as needed.

### Initializing collections

The new generator syntax dovetails nicely with the Julia convention that collections have constructors that accept an iterable yielding the values the collection should contain. In its simplest form, this looks something like this:

    julia> IntSet([1, 4, 9, 16, 25, 36, 49, 64])
    IntSet([1, 4, 9, 16, 25, 36, 49, 64])

This array of squares is tedious and error prone to write out by hand and would be much easier to generate with an array comprehension:

    julia> IntSet([k^2 for k = 1:8])
    IntSet([1, 4, 9, 16, 25, 36, 49, 64])

This comprehension creates the same array of integers that we manually entered in the first case above. Creating an array object is not optimal, however – it would be better still to simple generate the desired squares as they are inserted into the `IntSet` being constructed. This is precisely what a generator expression allows:

    julia> Set(k^2 for k = 1:8) # no temporary array!
    IntSet([1, 4, 9, 16, 25, 36, 49, 64])

Note that the "array" printed when showing the resulting `IntSet` doesn't really exist and is never constructed in this case – it's merely how an `IntSet` is displayed. Let's benchmark these two constructions:

    julia> using BenchmarkTools

    julia> @benchmark IntSet([k^2 for k = 1:8])
    BenchmarkTools.Trial:
      samples:          10000
      evals/sample:     772
      time tolerance:   5.00%
      memory tolerance: 1.00%
      memory estimate:  320.00 bytes
      allocs estimate:  5
      minimum time:     163.00 ns (0.00% GC)
      median time:      199.00 ns (0.00% GC)
      mean time:        245.18 ns (12.95% GC)
      maximum time:     5.36 μs (92.47% GC)

    julia> @benchmark IntSet(k^2 for k = 1:8)
    BenchmarkTools.Trial:
      samples:          10000
      evals/sample:     925
      time tolerance:   5.00%
      memory tolerance: 1.00%
      memory estimate:  160.00 bytes
      allocs estimate:  3
      minimum time:     114.00 ns (0.00% GC)
      median time:      139.00 ns (0.00% GC)
      mean time:        165.74 ns (11.48% GC)
      maximum time:     4.82 μs (93.20% GC)

I'm using the `BenchmarkTools` package here instead of hand-rolled timing loops. `BenchmarkTools` has been carefully designed to avoid many of the common pitfalls of benchmarking code and give sound statistical estimates of how much time and memory code being benchmarked takes to run. As you can see here, the version that allocates a temporary array uses twice as much memory and is 50% slower than the version using a generator expression.

The use of generator expressions to construct `Dict` objects deserves some special attention because the new general approach replaces what previously required special syntax. In Julia 0.4 and before, there was a special comprehension-like syntax for constructing `Dict` values:

    julia> ["*"^k => k for k = 1:10] # old syntax, deprecated in 0.5
    Dict{String,Int64} with 10 entries:
      "**********" => 10
      "***"        => 3
      "*******"    => 7
      "********"   => 8
      "*"          => 1
      "**"         => 2
      "****"       => 4
      "*********"  => 9
      "*****"      => 5
      "******"     => 6

While this syntax is convenient, it is completely replaced by simply allowing the `Dict` constructor to take a generator expression producing key-value pairs:

    julia> Dict("*"^k => k for k = 1:10)
    Dict{String,Int64} with 10 entries:
      "**********" => 10
      "***"        => 3
      "*******"    => 7
      "********"   => 8
      "*"          => 1
      "**"         => 2
      "****"       => 4
      "*********"  => 9
      "*****"      => 5
      "******"     => 6

Recall that since Julia 0.4, `a => b` has been syntax for `Pair` object, so the expression `"*"^k => k for k = 1:10` is a generator of `Pair` values, each of which associates a single key with a value. The `Dict` constructor iterates through these, inserting each pair into the new dictionary.

In scripting languages, the built-in dictionary type tends to be very special, and deeply integrated into the language, including having special syntax. We initially thought this might make sense in Julia, but in this aspect Julia turns out to be more like Java or C++ than Python or Lua. Julia's `Dict` is a perfectly mundane type, which just happens to be defined in the standard library. It's common for Julia programmers to swap one associative array implementation for another one with different properties and tradeoffs. It might make sense, for example, to replace the unsorted hash-table-based `Dict` with a tree-based implementation, exposing the same dictionary-like interface, but storing keys in sorted order with different efficiency tradeoffs between dictionary operations. When there is special syntax for the `Dict` type, this kind of change requires non-trivial code rewriting, switching to a fundamentally different syntax. Since `Dict` now uses a syntax available to any data structure, changing dictionary implementations is now a simple matter of search-and-replace. This change further advances one of the fundamental princples around which Julia is designed: that user-defined types are just as first-class as the built-in ones.

### Filtering and nesting

Julia's array comprehensions have always supported some advanced features such as iterating with multiple variables to produce multidimensional array. For example, we can

### Inference-independence

### Generator expressions

Comprehension-like syntax for yielding values.

## Arrays

### Syntax for vectorized function calls with broadcasting and loop fusion

### "Dim sum" slicing

APL-style array slicing.

### Better array views

### Improved custom array type support

## Strings

### Simplification and unification

## Other

- prime and combinatorics functionality moved into packages
- upgrade of LLVM from version 3.3 to version 3.7.1
- improved [ARM] support and initial support for [Power]
- experimental, scalable threading support
- a powerful interactive debugger

[ARM]: https://en.wikipedia.org/wiki/ARM_architecture
[Power]: https://en.wikipedia.org/wiki/Power_Architecture
