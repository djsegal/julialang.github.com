---
layout: post
title:  Julia 0.5 Highlights
author: Stefan Karpinski
---

Julia 0.5 is a pivotal release. It introduces more transformative features than any release since the first official version. Moreover, several of these features set the stage for even more to come in the [lead up to Julia 1.0](https://www.youtube.com/watch?v=5gXMpbY1kJY). In this post, we'll go through some of the major changes in 0.5, including improvements to functional programming, comprehensions, generators, arrays, strings, the standard library, and tooling.

## Functions

Julia has always been a functional language in the technical sense: functions are values that can be passed to and from other functions (i.e. [higher-order functions](https://en.wikipedia.org/wiki/Higher-order_function)) and there is full support for [lambdas](https://en.wikipedia.org/wiki/Anonymous_function). Before this release, however, anonymous and higher-order functions came with a significant performance cost, and in a language that targets high-performance technical computing, that's a serious limitation. So the Julia standard library and ecosystem have been rife with work-arounds to get the expressiveness of functional programming without the performance problems. But the right solution, of course, is to make functional programming fast – ideally just as fast as the optimal hand-written version of your code would be. In Julia 0.5, it is. And that changes everything.

This change is so important that there will be a separate blog post about it in the coming weeks, explaining how higher-order functions and lambdas have been made so efficient, as well as detailing the kinds of zero-cost abstractions these changes enable in Julia 0.5. But for now, I'll just tease with a little timing comparison. First, some definitions – they're the same in either version of Julia:

    v = rand(10^7);                   # 10 million random values
    double_it_vec(v) = 2v             # vectorized doubling of input
    double_it_map(v) = map(x->2x, v)  # map a lambda over input

Now, a timing comparison in Julia 0.4:

    julia> VERSION
    v"0.4.7"

    julia> mean([@elapsed(double_it_vec(v)) for _=1:100])
    0.024444888209999998

    julia> mean([@elapsed(double_it_map(v)) for _=1:100])
    0.5515606454499999

As you can see, the functional version using `map` is over 22 times slower than the vectorized form that uses specialized generated code for maximal speed. Next, the same comparison in Julia 0.5:

    julia> VERSION
    v"0.5.0"

    julia> mean([@elapsed(double_it_vec(v)) for _=1:100])
    0.024549842180000003

    julia> mean([@elapsed(double_it_map(v)) for _=1:100])
    0.023871925960000002

In Julia 0.5, the version defined in terms of `map` is as fast than the vectorized method (and maybe even faster, which isn't impossible since the lambda is specialized on the value 2). In this case, writing `2v` happens to be more convenient than writing `map(x->2x, v)`, and you can keep using vectorized forms when they're more convenient. However, there are many cases where functional constructs are more general, clearer, or more convenient, and now also efficient.

### Ambiguous methods

One design decision that any multiple dispatch language must make is how to handle dispatch ambiguities: cases where none of the methods applicable to a given set of arguments is more specific than the rest. Suppose, for example, that a generic function, `f`, has the following methods:

    f(a::Int, b::Real) = 1
    f(a::Real, b::Int) = 2

In Julia 0.4 and earlier, the second method definition causes a method ambiguity warning:

    WARNING: New definition
        f(Real, Int64) at none:1
    is ambiguous with:
        f(Int64, Real) at none:1.
    To fix, define
        f(Int64, Int64)
    before the new definition.

This warning is clear and gets right to the point: the case `f(a, b)` where `a` and `b` are of type `Int` (an alias for `Int64` on 64-bit systems) is ambiguous. Evaluating `f(3,4)` calls the first method of `f` – but this behavior is undefined. Giving a warning whenever methods *could* be ambiguous is a fairly conservative choice: it urges people to define a method covering the ambiguous intersection before even defining the methods that overlap. When we decided to emit ambigous method warnings, we hoped that people would avoid ambigous cases and all would be well in the world.

Emiting warnings for method ambiguities turns out to be both too strict and too lenient. It's far too easy for ambiguities to arise when common generic functions serve as extension points across unrelated packages. When many packages extend the same generic functions, it's *very* common for the methods added to have some ambiguous overlap. This happens even when each package has no ambiguities on its own. Worse still, slight changes to one package can introduce ambiguities elsewhere, resulting in the least fun game of whack-a-mole ever. At the same time, the fact that ambiguities *only* cause warnings means that people learn to ignore them, which is annoying at best, and dangerous at worst: it's far too easy for a real problem to be hidden by a barrage of insignificant ambiguity warnings. In particular, on 0.4 and earlier if an ambiguous method is actually called, no error occurs. Instead, one of the possible methods is called, based on the order in which methods were defined – which is essentially arbitrary when they come from different packages. Often called method works – it does apply, after all – but this is clearly not the right thing to do.

The solution is simple: in Julia 0.5 the existence of potential ambiguities is fine, but actually calling an ambiguous method is an immediate error. The method definitions for `f`, which previously triggered a warning, are now silent, but *calling* `f` with two `Int` arguments is a method dispatch error:

    julia> f(3, 4)
    ERROR: MethodError: f(::Int64, ::Int64) is ambiguous. Candidates:
      f(a::Real, b::Int64) at REPL[2]:1
      f(a::Int64, b::Real) at REPL[1]:1
     in eval(::Module, ::Any) at ./boot.jl:231
     in macro expansion at ./REPL.jl:92 [inlined]
     in (::Base.REPL.##1#2{Base.REPL.REPLBackend})() at ./event.jl:46

This improves the experience of using the Julia package ecosystem considerably, while also making Julia safer and more reliable. No more torrent of insignificant ambiguity warnings. No more playing ambiguity whack-a-mole when someone else refactors their code and accidentally introduces ambuities in yours. No more risk that a method call could be silently broken because of ambiguity warnings that we've all learned to ignore.

### Return type annotations

A long-requested feature has been the ability to annotate method definitions with an explicit return type. This aids the clarity of code, serves as self-documentation, helps the compiler reason about code, and ensures that return types are what the programmer intends and expects. In Julia 0.5, you can annotate method definitions with a return type, like so:

    function clip{T<:Real}(x::T, lo::Real, hi::Real)::T
        if x < lo
            return lo
        elseif x > hi
            return hi
        else
            return x
        end
    end

This annotation on this `clip` method has the effect of inserting implicit calls to `x->convert(T, x)` at each return point of the method. It has no effect on any other method of `clip`. In this case, the annotation ensures that this method always returns a value of the same type as `x`, regardless of what the types of `lo` and `hi` are:

    julia> clip(0.5, 1, 2)
    1.0

    julia> clip(1.5, 1, 2)
    1.5

    julia> clip(2.5, 1, 2)
    2.0

You'll note that the annotated return type here is `T`, which is a type parameter of the `clip` method. Not only is that allowed, but the return type can be an arbitrary expression of argument values, type parameters, and values from outer scopes. For example, here is a variation that promotes its arguments:

    function clip2(x::Real, lo::Real, hi::Real)::promote_type(typeof(x), typeof(lo), typeof(hi))
        if x < lo
            return lo
        elseif x > hi
            return hi
        else
            return x
        end
    end

    julia> clip2(2, 1, 3)
    2

    julia> clip2(2, 1, 13//5)
    2//1

    julia> clip2(2.5, 1, 13//5)
    2.5

Return type annotations are a fairly simply syntactic rewrite, but they make it easier to write methods with consistent and predicatble return types. If different branches of your code can lead to slightly different return types, the fix is now as simple as putting a single type annotation on the entire method.

## Comprehensions & Generators

In the section above on functional programming performance, we used an array comprehension to time an expression repeatedly, producing an array of elapsed times, and applying the `mean` function to that array to compute an average elapsed time:

    julia> mean([@elapsed(double_it_map(v)) for _=1:100])
    0.02431330791

But allocating an array of times here is unneccessary: an average can be computed over streamed data, one value at a time, accumulating only the sum and count of values. In other words, this computation could be expressed with constant memory overhead by interleaving the production of values with the code to compute their mean. Prior to Julia 0.5, the most straightforward way to express such an interleaved computation was to manually perform the interleaving (aka "cut and paste"). In Julia 0.5, if you simply omit the square brackets around an array comprehension, you get a *generator expression*, which instead of producing an array of values, can be iterated over, yielding one value at a time. Since the `mean` function works with arbitrary iterable objects – including generators – expressing an interleaved mean computation using constant memory is now as simple as deleting `[` and `]`:

    julia> mean(@elapsed(double_it_map(v)) for _=1:100)
    0.024382122609999998

This avoids allocating a temporary array of elapsed times entirely, instead evaluating the inner expression, `@elapsed(double_it_map(v))`, each time the `mean` function is ready to accept a new value. In this case, the allocation saved is trivial, but it transforms this code from *O(n)* in the number of samples to *O(1)*. It doesn't take much imagination to think of situations where such a reduction in asymtotic memory usage is crucial. The similar syntax between array comprehensions and generator expressions makes it trivial to move back and forth between the two styles of computation as needed.

### Initializing collections

The new generator syntax dovetails particularly nicely with the Julia convention for constructing collections: to make a new collection, you call the constructor with a single iterable argument, which yields the values you want in the new collection. In its simplest form, this looks something like:

    julia> IntSet([1, 4, 9, 16, 25, 36, 49, 64])
    IntSet([1, 4, 9, 16, 25, 36, 49, 64])

In this input expression, an array of integers is passed to the `IntSet` constructor to create an object representing that set of integers, which in this case happen to be small squares. Once constructed, the `IntSet` object no longer refers to the original array of integers. Instead, it uses a bitmask to efficiently store and operate on sets of positive integers. It displays itself as you would construct it from an array of integers, but that's merely for convenience – there's no actual array anymore.

Now, I'm a human (no blogbots here) and I find typing out even short sequences of perfect squares tedious and error prone – despite a math degree, I'm awful at arithmetic. It would be much easier to generate the values to go in this `IntSet` with an array comprehension:

    julia> IntSet([k^2 for k = 1:8])
    IntSet([1, 4, 9, 16, 25, 36, 49, 64])

This comprehension creates the same array of integers that we manually entered in the first case above. Creating an array object is unnecessary, though – it would be even better to generate the desired squares as they are inserted into the `IntSet` being constructed. Which, of course, is precisely what generator expressions allow:

    julia> Set(k^2 for k = 1:8) # no temporary array!
    IntSet([1, 4, 9, 16, 25, 36, 49, 64])

Let's benchmark these two constructions:

    julia> using BenchmarkTools

    julia> @benchmark IntSet([k^2 for k = 1:8])
    BenchmarkTools.Trial:
      samples:          10000
      evals/sample:     772
      time tolerance:   5.00%
      memory tolerance: 1.00%
      memory estimate:  320.00 bytes
      allocs estimate:  5
      minimum time:     163.00 ns (0.00% GC)
      median time:      199.00 ns (0.00% GC)
      mean time:        245.18 ns (12.95% GC)
      maximum time:     5.36 μs (92.47% GC)

    julia> @benchmark IntSet(k^2 for k = 1:8)
    BenchmarkTools.Trial:
      samples:          10000
      evals/sample:     925
      time tolerance:   5.00%
      memory tolerance: 1.00%
      memory estimate:  160.00 bytes
      allocs estimate:  3
      minimum time:     114.00 ns (0.00% GC)
      median time:      139.00 ns (0.00% GC)
      mean time:        165.74 ns (11.48% GC)
      maximum time:     4.82 μs (93.20% GC)

I'm using the `BenchmarkTools` package here instead of hand-rolled timing loops – `BenchmarkTools` has been carefully designed to avoid many of the common pitfalls of benchmarking code and provide sound statistical estimates of how much time and memory code being benchmarked takes to run. As you can see here, the version that allocates a temporary array uses twice as much memory and is 50% slower than the version using a generator expression.

#### Constructing dictionaries

The use of generator expressions to construct dictionaries deserves some special attention since generator expressions completely eliminate the need for special syntax. In older Julias, there has been a special comprehension syntax for constructing `Dict` objects:

    julia> ["*"^k => k for k = 1:10] # old syntax, deprecated in 0.5
    Dict{String,Int64} with 10 entries:
      "**********" => 10
      "***"        => 3
      "*******"    => 7
      "********"   => 8
      "*"          => 1
      "**"         => 2
      "****"       => 4
      "*********"  => 9
      "*****"      => 5
      "******"     => 6

This syntax is convenient, but the same effect can now be achieved without special syntax, simply by passing a generator expression producing key-value pairs to the `Dict` constructor:

    julia> Dict("*"^k => k for k = 1:10)
    Dict{String,Int64} with 10 entries:
      "**********" => 10
      "***"        => 3
      "*******"    => 7
      "********"   => 8
      "*"          => 1
      "**"         => 2
      "****"       => 4
      "*********"  => 9
      "*****"      => 5
      "******"     => 6

Since Julia 0.4, `a => b` has been syntax for constructing a `Pair` object with key `a` and value `b`, so the expression `"*"^k => k for k = 1:10` is a generator of pairs. The `Dict` constructor iterates through these pairs, inserting each key into the new dictionary, mapping to the corresponding value. In the future, the now-deprecated `["*"^k => k for k = 1:10]` will stop having a special meaning and will produce an array of `Pair` values.

Some motivation may be in order for a syntax change that makes constructing a dictionary harder than some people feel it should be. In scripting languages, the built-in dictionary type tends to be very special, and deeply integrated into the language, including having special syntax. We initially thought this might make sense in Julia, but in this aspect Julia turns out to be more like Java or C++ than Python or Lua. Julia's `Dict` is a perfectly mundane type, which just happens to be defined in the standard library. It's common for Julia programmers to swap one associative array implementation for another one with different properties and tradeoffs. It might make sense, for example, to replace the unsorted hash-table-based `Dict` with a tree-based implementation, exposing the same dictionary-like interface, but storing keys in sorted order with different efficiency tradeoffs between dictionary operations. When there is special syntax for the `Dict` type, this kind of change requires non-trivial code rewriting, switching to a fundamentally different syntax. Since `Dict` now uses a syntax available to any data structure, changing dictionary implementations is now a simple matter of search-and-replace. This change further advances one of the fundamental princples around which Julia is designed: that user-defined types are just as first-class as the built-in ones.

### Filtering and nesting

Julia's array comprehensions have always supported some advanced features such as iterating with multiple variables to produce multidimensional array. For example, we can

### Inference-independence

### Generator expressions

Comprehension-like syntax for yielding values.

## Arrays

### Syntax for vectorized function calls with broadcasting and loop fusion

### "Dim sum" slicing

APL-style array slicing.

### Better array views

### Improved custom array type support

## Strings

### Simplification and unification

## Other

- prime and combinatorics functionality moved into packages
- upgrade of LLVM from version 3.3 to version 3.7.1
- improved [ARM] support and initial support for [Power]
- experimental, scalable threading support
- a powerful interactive debugger

[ARM]: https://en.wikipedia.org/wiki/ARM_architecture
[Power]: https://en.wikipedia.org/wiki/Power_Architecture
