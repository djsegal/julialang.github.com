---
layout: post
title:  Julia 0.5 Highlights
author: Stefan Karpinski
---

Julia 0.5 is a pivotal release. It introduces more transformative features than any release since Julia's initial public release. Moreover, several of these features set the stage for even more to come in the [lead up to Julia 1.0](https://www.youtube.com/watch?v=5gXMpbY1kJY). In this post, we'll go through some of the major changes in 0.5, including improvements to functional programming, comprehensions, generators, arrays, strings, the standard library, and tooling.

## Functions

Julia has always been a functional language in the technical sense: functions are values that can be passed to and from other functions (i.e. [higher-order functions](https://en.wikipedia.org/wiki/Higher-order_function)) and there is full support for [lambdas](https://en.wikipedia.org/wiki/Anonymous_function). Before this release, however, anonymous and higher-order functions came with a significant performance cost, and in a language that targets high-performance technical computing, that's a problem. So the Julia standard library and ecosystem have been rife with work-arounds to get the expressiveness of functional programming without the performance problems. But the right solution, of course, is to just make functional programming fast – ideally just as fast as the optimal hand-written version of your code would be. In Julia 0.5, it is. And that changes everything.

This change is so important that there will be a separate blog post about it in the coming weeks, explaining how it was accomplished and what kinds of zero-cost abstractions it enables in Julia 0.5, but for now, I'll just tease with a little timing comparison:

    julia> v = rand(10^7);
    
    julia> double_it_vec(v) = 2v
    double_it_vec (generic function with 1 method)
    
    julia> double_it_map(v) = map(x->2x, v)
    double_it_map (generic function with 1 method)
    
    julia> mean([@elapsed(double_it_vec(v)) for _=1:100])
    0.02426630012
    
    julia> mean([@elapsed(double_it_map(v)) for _=1:100])
    0.023419441759999996

Defining a `double_it` function in terms of a higher-order construct like `map` is now as fast (or even faster) than using a specialize method for vectorized scaling. On 0.4, by constrast, using `map` like this is over 200 times slower than the vectorized version. In this case, writing `2v` is more convenient, and you can keep doing that when it's easier, but many constructs that were previously speclized via code generation, can now simply be *defined* in terms of generic functional constructs. The result is more elegant, more concise, and at least as efficient.

### Return type annotations

You can now annotate method definitions with a return type, like so:

    function clip{T<:Real}(x::T, lo::Real, hi::Real)::T
        if x < lo
            return lo
        elseif x > hi
            return hi
        else
            return x
        end
    end

This has the effect of inserting implicit calls to `convert` to `T` at each return point, in this case ensuring that `clip` always returns a value of the same type as `x`, regardless of the type of `lo` and `hi`:

    julia> clip(0.5, 1, 2)
    1.0
    
    julia> clip(1.5, 1, 2)
    1.5
    
    julia> clip(2.5, 1, 2)
    2.0

You may have noticed that the return type here is `T`, which is a type parameter of the `clip` method. Not only is that allowed, but the return type can be an arbitrary expression of values from the outer scope, argument values, and type parameters. For example:

    function clip2(x::Real, lo::Real, hi::Real)::promote_type(typeof(x), typeof(lo), typeof(hi))
        if x < lo
            return lo
        elseif x > hi
            return hi
        else
            return x
        end
    end

    julia> clip2(2, 1, 3)
    2

    julia> clip2(2, 1, 13//5)
    2//1

    julia> clip2(2.5, 1, 13//5)
    2.5

Return type annotations makes it easier to write methods with consistent and predicatble return types – if different branches of your code lead to slightly different return types, the fix is now as simple as putting a single type annotation on the entire method.

### No more ambiguous method warnings

One design decision that any multiple dispatch language must make is how to handle dispatch ambiguities – cases where none of the methods applicable to a given set of arguments is strictly more specific than the rest. For example, suppose a generic function, `f` has the following methods:

    f(a::Int, b::Real) = 1
    f(a::Real, b::Int) = 2

In Julia 0.4 and earlier, when the second method is defined, Julia prints a method ambiguity warning:

    WARNING: New definition
        f(Real, Int64) at none:1
    is ambiguous with:
        f(Int64, Real) at none:1.
    To fix, define
        f(Int64, Int64)
    before the new definition.

This is a fairly conservative choice – it urges people to define a method covering the ambiguous intersection *before* defining these two methods. When this choice was made, we hoped that people would define explicit behaviors for all ambigous cases and all would be well in the world.

Warnings for method ambiguities has turned out to be impractical, however – especially for generic methods that are extended by many different packages. Unrelated packages commonly load independently without any ambiguities, yet when both are loaded simultaneously, ambiguities are created. In Julia 0.4 and earlier, this produced an alarming cascade of warnings. Moreover, these ambiguities cases are generally unlikely to actually occur since the types are unrelated – and if they do occur, a runtime error is the most appropriate recourse. Accordingly, in Julia 0.5 these method definitions for `f` produce no warnings; instead, ambiguous calls raise runtime errors:

    julia> f(3, 4)
    ERROR: MethodError: f(::Int64, ::Int64) is ambiguous. Candidates:
      f(a::Real, b::Int64) at REPL[2]:1
      f(a::Int64, b::Real) at REPL[1]:1
     in eval(::Module, ::Any) at ./boot.jl:231
     in macro expansion at ./REPL.jl:92 [inlined]
     in (::Base.REPL.##1#2{Base.REPL.REPLBackend})() at ./event.jl:46

This improves the experience of using the Julia package ecosystem considerably since loading unrelated packages no longer runs the risk of spewing forth a flood of ambiguity warnings. And of course, fewer unnecessary warnings means that real warnings that you *should* be concerned about are less likely to get lost in the noise, which makes for safer and more reliable programs.

## Comprehensions & Generators

In examples above, we used an array comprehension to time an expression multiple times, producing an array of elapsed times. We then applied the `mean` function to that array to get an average elapsed time. But an average can easily be computed over streamed data, accumulating only the sum and count of values, so this code could be expressed with constant overhead by interleaving the computation of the mean with the evaluation of the expression producing values. Prior to Julia 0.5, the easiest way to express a streamed computation like this was to write out an explicit for loop. In Julia 0.5, on the other hand, if you leave the `[` and `]` around an array comprehension out, you get a *generator expression*, which instead of producing an array of values, can be iterated over yielding one value at a time. Since many standard library functions work with arbitrary iterable collections – including generators – writing the streamed version of this computation, and many others, is now as easy as deleting two square brackets:

    julia> mean(@elapsed(double_it_map(v)) for _=1:100)
    0.022724940119999995

This avoids allocating a temporary array of elapsed times: instead the expression `@elapsed(double_it_map(v))` gets evaluated each time the `mean` function is ready to accept a new value. The syntactic similarity to array comprehensions makes it trivial to move back and forth between the two styles of computation as needed.

### Filtering and nesting

Julia's array comprehensions have always supported some advanced features such as iterating with multiple variables to produce multidimensional array. For example, we can 

### Inference-independence

### Generator expressions

Comprehension-like syntax for yielding values.

## Arrays

### Syntax for vectorized function calls with broadcasting and loop fusion

### "Dim sum" slicing

APL-style array slicing.

### Better array views

### Improved custom array type support

## Strings

### Simplification and unification

## Other

- prime and combinatorics functionality moved into packages
- upgrade of LLVM from version 3.3 to version 3.7.1
- improved [ARM] support and initial support for [Power]
- experimental, scalable threading support
- a powerful interactive debugger

[ARM]: https://en.wikipedia.org/wiki/ARM_architecture
[Power]: https://en.wikipedia.org/wiki/Power_Architecture
