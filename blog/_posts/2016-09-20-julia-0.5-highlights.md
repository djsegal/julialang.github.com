---
layout: post
title:  Julia 0.5 Highlights
author: Stefan Karpinski
---

Julia 0.5 is a pivotal release. It introduces more transformative features than any release since the first official version. Moreover, several of these features set the stage for even more to come in the [lead up to Julia 1.0](https://www.youtube.com/watch?v=5gXMpbY1kJY). In this post, we'll go through some of the major changes in 0.5, including improvements to functional programming, comprehensions, generators, arrays, strings, the standard library, and tooling.

## Functions

Julia has always been a functional language in the technical sense: functions are values that can be passed to and from other functions (i.e. [higher-order functions](https://en.wikipedia.org/wiki/Higher-order_function)) and there is full support for [lambdas](https://en.wikipedia.org/wiki/Anonymous_function). Before this release, however, anonymous and higher-order functions came with a significant performance cost, and in a language that targets high-performance technical computing, that's a serious limitation. So the Julia standard library and ecosystem have been rife with work-arounds to get the expressiveness of functional programming without the performance problems. But the right solution, of course, is to make functional programming fast – ideally just as fast as the optimal hand-written version of your code would be. In Julia 0.5, it is. And that changes everything.

This change is so important that there will be a separate blog post about it in the coming weeks, explaining how higher-order functions and lambdas have been made so efficient, as well as detailing the kinds of zero-cost abstractions these changes enable in Julia 0.5. But for now, I'll just tease with a little timing comparison. First, some definitions – they're the same in either version of Julia:

    v = rand(10^7);                   # 10 million random values
    double_it_vec(v) = 2v             # vectorized doubling of input
    double_it_map(v) = map(x->2x, v)  # map a lambda over input

Now, a timing comparison in Julia 0.4:

    julia> VERSION
    v"0.4.7"

    julia> mean([@elapsed(double_it_vec(v)) for _=1:100])
    0.024444888209999998

    julia> mean([@elapsed(double_it_map(v)) for _=1:100])
    0.5515606454499999

As you can see, the functional version using `map` is over 22 times slower than the vectorized form that uses specialized generated code for maximal speed. Next, the same comparison in Julia 0.5:

    julia> VERSION
    v"0.5.0"

    julia> mean([@elapsed(double_it_vec(v)) for _=1:100])
    0.024549842180000003

    julia> mean([@elapsed(double_it_map(v)) for _=1:100])
    0.023871925960000002

In Julia 0.5, the version defined in terms of `map` is as fast than the vectorized method (and maybe even faster, which isn't impossible since the lambda is specialized on the value 2). In this case, writing `2v` happens to be more convenient than writing `map(x->2x, v)`, and you can keep using vectorized forms when they're more convenient. However, there are many cases where functional constructs are more general, clearer, or more convenient, and now also efficient.

### Ambiguous methods

One design decision that any multiple dispatch language must make is how to handle dispatch ambiguities: cases where none of the methods applicable to a given set of arguments is more specific than the rest. Suppose, for example, that a generic function, `f`, has the following methods:

    f(a::Int, b::Real) = 1
    f(a::Real, b::Int) = 2

In Julia 0.4 and earlier, the second method definition causes a method ambiguity warning:

    WARNING: New definition
        f(Real, Int64) at none:1
    is ambiguous with:
        f(Int64, Real) at none:1.
    To fix, define
        f(Int64, Int64)
    before the new definition.

This warning is clear and gets right to the point: the case `f(a, b)` where `a` and `b` are of type `Int` (an alias for `Int64` on 64-bit systems) is ambiguous. Evaluating `f(3,4)` calls the first method of `f` – but this behavior is undefined. Giving a warning whenever methods *could* be ambiguous is a fairly conservative choice: it urges people to define a method covering the ambiguous intersection before even defining the methods that overlap. When we decided to emit ambigous method warnings, we hoped that people would avoid ambigous cases and all would be well in the world.

Emiting warnings for method ambiguities turns out to be both too strict and too lenient. It's far too easy for ambiguities to arise when common generic functions serve as extension points across unrelated packages. When many packages extend the same generic functions, it's *very* common for the methods added to have some ambiguous overlap. This happens even when each package has no ambiguities on its own. Worse still, slight changes to one package can introduce ambiguities elsewhere, resulting in the least fun game of whack-a-mole ever. At the same time, the fact that ambiguities *only* cause warnings means that people learn to ignore them, which is annoying at best, and dangerous at worst: it's far too easy for a real problem to be hidden by a barrage of insignificant ambiguity warnings. In particular, on 0.4 and earlier if an ambiguous method is actually called, no error occurs. Instead, one of the possible methods is called, based on the order in which methods were defined – which is essentially arbitrary when they come from different packages. Often called method works – it does apply, after all – but this is clearly not the right thing to do.

The solution is simple: in Julia 0.5 the existence of potential ambiguities is fine, but actually calling an ambiguous method is an immediate error. The method definitions for `f`, which previously triggered a warning, are now silent, but *calling* `f` with two `Int` arguments is a method dispatch error:

    julia> f(3, 4)
    ERROR: MethodError: f(::Int64, ::Int64) is ambiguous. Candidates:
      f(a::Real, b::Int64) at REPL[2]:1
      f(a::Int64, b::Real) at REPL[1]:1
     in eval(::Module, ::Any) at ./boot.jl:231
     in macro expansion at ./REPL.jl:92 [inlined]
     in (::Base.REPL.##1#2{Base.REPL.REPLBackend})() at ./event.jl:46

This improves the experience of using the Julia package ecosystem considerably, while also making Julia safer and more reliable. No more torrent of insignificant ambiguity warnings. No more playing ambiguity whack-a-mole when someone else refactors their code and accidentally introduces ambuities in yours. No more risk that a method call could be silently broken because of ambiguity warnings that we've all learned to ignore.

### Return type annotations

A long-requested feature has been the ability to annotate method definitions with an explicit return type. This aids the clarity of code, serves as self-documentation, helps the compiler reason about code, and ensures that return types are what the programmer intends and expects. You can now annotate method definitions with a return type, like so:

    function clip{T<:Real}(x::T, lo::Real, hi::Real)::T
        if x < lo
            return lo
        elseif x > hi
            return hi
        else
            return x
        end
    end

The return type annotation `::T` has the effect of inserting implicit calls to `x->convert(T, x)` at each return point of the method. In this case, this ensures that `clip` always returns a value of the same type as `x`, regardless of what the type of the provided `lo` and `hi` values are:

    julia> clip(0.5, 1, 2)
    1.0

    julia> clip(1.5, 1, 2)
    1.5

    julia> clip(2.5, 1, 2)
    2.0

You may notice that the return type here is `T`, which is a type parameter of the `clip` method. Not only is that allowed, but the return type can be an arbitrary expression of argument values, type parameters, and values from outer scopes. For example:

    function clip2(x::Real, lo::Real, hi::Real)::promote_type(typeof(x), typeof(lo), typeof(hi))
        if x < lo
            return lo
        elseif x > hi
            return hi
        else
            return x
        end
    end

    julia> clip2(2, 1, 3)
    2

    julia> clip2(2, 1, 13//5)
    2//1

    julia> clip2(2.5, 1, 13//5)
    2.5

Return type annotations makes it easier to write methods with consistent and predicatble return types – if different branches of your code lead to slightly different return types, the fix is now as simple as putting a single type annotation on the entire method.

## Comprehensions & Generators

In examples above, we used an array comprehension to time an expression multiple times, producing an array of elapsed times. We then applied the `mean` function to that array to get an average elapsed time. But an average can easily be computed over streamed data, accumulating only the sum and count of values, so this code could be expressed with constant overhead by interleaving the computation of the mean with the evaluation of the expression producing values. Prior to Julia 0.5, the easiest way to express a streamed computation like this was to write out an explicit for loop. In Julia 0.5, on the other hand, if you leave the `[` and `]` around an array comprehension out, you get a *generator expression*, which instead of producing an array of values, can be iterated over yielding one value at a time. Since many standard library functions work with arbitrary iterable collections – including generators – writing the streamed version of this computation, and many others, is now as easy as deleting two square brackets:

    julia> mean(@elapsed(double_it_map(v)) for _=1:100)
    0.022724940119999995

This avoids allocating a temporary array of elapsed times. Instead the expression `@elapsed(double_it_map(v))` is evaluated each time the `mean` function is ready to accept a new value. The syntactic similarity between array comprehensions and generator expressions makes it trivial to move back and forth between the two styles of computation as needed.

### Initializing collections

The new generator syntax dovetails nicely with the Julia convention that collections have constructors that accept an iterable yielding the values the collection should contain. In its simplest form, this looks something like this:

    julia> IntSet([1, 4, 9, 16, 25, 36, 49, 64])
    IntSet([1, 4, 9, 16, 25, 36, 49, 64])

This array of squares is tedious and error prone to write out by hand and would be much easier to generate with an array comprehension:

    julia> IntSet([k^2 for k = 1:8])
    IntSet([1, 4, 9, 16, 25, 36, 49, 64])

This comprehension creates the same array of integers that we manually entered in the first case above. Creating an array object is not optimal, however – it would be better still to simple generate the desired squares as they are inserted into the `IntSet` being constructed. This is precisely what a generator expression allows:

    julia> Set(k^2 for k = 1:8) # no temporary array!
    IntSet([1, 4, 9, 16, 25, 36, 49, 64])

Note that the "array" printed when showing the resulting `IntSet` doesn't really exist and is never constructed in this case – it's merely how an `IntSet` is displayed. Let's benchmark these two constructions:

    julia> using BenchmarkTools

    julia> @benchmark IntSet([k^2 for k = 1:8])
    BenchmarkTools.Trial:
      samples:          10000
      evals/sample:     772
      time tolerance:   5.00%
      memory tolerance: 1.00%
      memory estimate:  320.00 bytes
      allocs estimate:  5
      minimum time:     163.00 ns (0.00% GC)
      median time:      199.00 ns (0.00% GC)
      mean time:        245.18 ns (12.95% GC)
      maximum time:     5.36 μs (92.47% GC)

    julia> @benchmark IntSet(k^2 for k = 1:8)
    BenchmarkTools.Trial:
      samples:          10000
      evals/sample:     925
      time tolerance:   5.00%
      memory tolerance: 1.00%
      memory estimate:  160.00 bytes
      allocs estimate:  3
      minimum time:     114.00 ns (0.00% GC)
      median time:      139.00 ns (0.00% GC)
      mean time:        165.74 ns (11.48% GC)
      maximum time:     4.82 μs (93.20% GC)

I'm using the `BenchmarkTools` package here instead of hand-rolled timing loops. `BenchmarkTools` has been carefully designed to avoid many of the common pitfalls of benchmarking code and give sound statistical estimates of how much time and memory code being benchmarked takes to run. As you can see here, the version that allocates a temporary array uses twice as much memory and is 50% slower than the version using a generator expression.

#### Constructing dictionaries

The use of generator expressions to construct `Dict` objects deserves some special attention because the new general approach replaces what previously required special syntax. In Julia 0.4 and before, there was a special comprehension-like syntax for constructing `Dict` values:

    julia> ["*"^k => k for k = 1:10] # old syntax, deprecated in 0.5
    Dict{String,Int64} with 10 entries:
      "**********" => 10
      "***"        => 3
      "*******"    => 7
      "********"   => 8
      "*"          => 1
      "**"         => 2
      "****"       => 4
      "*********"  => 9
      "*****"      => 5
      "******"     => 6

While this syntax is convenient, it is completely replaced by simply allowing the `Dict` constructor to take a generator expression producing key-value pairs:

    julia> Dict("*"^k => k for k = 1:10)
    Dict{String,Int64} with 10 entries:
      "**********" => 10
      "***"        => 3
      "*******"    => 7
      "********"   => 8
      "*"          => 1
      "**"         => 2
      "****"       => 4
      "*********"  => 9
      "*****"      => 5
      "******"     => 6

Recall that since Julia 0.4, `a => b` has been syntax for `Pair` object, so the expression `"*"^k => k for k = 1:10` is a generator of `Pair` values, each of which associates a single key with a value. The `Dict` constructor iterates through these, inserting each pair into the new dictionary.

In scripting languages, the built-in dictionary type tends to be very special, and deeply integrated into the language, including having special syntax. We initially thought this might make sense in Julia, but in this aspect Julia turns out to be more like Java or C++ than Python or Lua. Julia's `Dict` is a perfectly mundane type, which just happens to be defined in the standard library. It's common for Julia programmers to swap one associative array implementation for another one with different properties and tradeoffs. It might make sense, for example, to replace the unsorted hash-table-based `Dict` with a tree-based implementation, exposing the same dictionary-like interface, but storing keys in sorted order with different efficiency tradeoffs between dictionary operations. When there is special syntax for the `Dict` type, this kind of change requires non-trivial code rewriting, switching to a fundamentally different syntax. Since `Dict` now uses a syntax available to any data structure, changing dictionary implementations is now a simple matter of search-and-replace. This change further advances one of the fundamental princples around which Julia is designed: that user-defined types are just as first-class as the built-in ones.

### Filtering and nesting

Julia's array comprehensions have always supported some advanced features such as iterating with multiple variables to produce multidimensional array. For example, we can

### Inference-independence

### Generator expressions

Comprehension-like syntax for yielding values.

## Arrays

### Syntax for vectorized function calls with broadcasting and loop fusion

### "Dim sum" slicing

APL-style array slicing.

### Better array views

### Improved custom array type support

## Strings

### Simplification and unification

## Other

- prime and combinatorics functionality moved into packages
- upgrade of LLVM from version 3.3 to version 3.7.1
- improved [ARM] support and initial support for [Power]
- experimental, scalable threading support
- a powerful interactive debugger

[ARM]: https://en.wikipedia.org/wiki/ARM_architecture
[Power]: https://en.wikipedia.org/wiki/Power_Architecture
